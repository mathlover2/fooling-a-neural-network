{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24de5bb7-b4c4-4ccc-abd9-5129ff08e7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn off Tensorflow warnings\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "## Key imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import pickle\n",
    "from math import prod\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product as iprod\n",
    "import random\n",
    "\n",
    "\n",
    "## Helper functions\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as imp:  # Overwrites any existing file.\n",
    "        res = pickle.load(imp)\n",
    "    return res\n",
    "\n",
    "def create_lstm_sample(scaled_sample):\n",
    "    if scaled_sample.shape[0] % 5 == 0:\n",
    "        s = scaled_sample\n",
    "    else:\n",
    "        s = scaled_sample[:-(scaled_sample.shape[0]%5)]\n",
    "    return np.stack(np.array_split(s, scaled_sample.shape[0]//5), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743c0b26-4693-4f81-8ac6-b08939a5e598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load objects \n",
    "\n",
    "lstm_test_data = load_object('lstm_test_data.pkl')\n",
    "lstm_test_labels = load_object('lstm_test_labels.pkl')\n",
    "lstm_test_data = np.concatenate([lstm_test_data[d] for d in ['browse','chat','mail','p2p']])\n",
    "lstm_test_labels = np.concatenate([lstm_test_labels[d] for d in ['browse','chat','mail','p2p']])\n",
    "scaler = load_object('scaler.pkl')\n",
    "\n",
    "stacked_cnn_lstm_sae = tf.keras.saving.load_model('stacked_cnn_lstm_sae.53.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c693f8-2cb9-405f-bac6-0a9a536bff26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "0 0\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "0 1\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "2 1\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "3 1\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "3 1\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "0 1\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "0 1\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "3 1\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "3 1\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "0 1\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "0 1\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "0 1\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "3 1\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1 1\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "0 3\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "### Get data for individual files/samples\n",
    "\n",
    "import glob\n",
    "\n",
    "data_path = \"Data/\"\n",
    "browse_data_path = data_path + \"browse/\"\n",
    "chat_data_path = data_path + \"chat/\"\n",
    "mail_data_path = data_path + \"mail/\"\n",
    "p2p_data_path =  data_path + \"p2p/\"\n",
    "data_paths = [browse_data_path, chat_data_path, mail_data_path, p2p_data_path]\n",
    "\n",
    "datasets = dict()\n",
    "sample_data = dict()\n",
    "sample_labels = dict()\n",
    "scaled_sliced_data = dict()\n",
    "test_samples = dict()\n",
    "\n",
    "for (index, path) in  enumerate(data_paths):\n",
    "    datasets[path] = list(glob.glob(path + \"*.pcap\"))\n",
    "    sample_data[path] = []\n",
    "\n",
    "    for sample_path in datasets[path]:\n",
    "        s = np.loadtxt(sample_path, delimiter=',').reshape((-1,6))\n",
    "        if s.shape[0] >= 25:\n",
    "            sample_data[path].append(s)\n",
    "\n",
    "# Scale and process for LSTM input\n",
    "    \n",
    "for path in data_paths:\n",
    "    scaled_sliced_data[path] = []\n",
    "    for s in sample_data[path]:\n",
    "        scaled_sliced_data[path].append(create_lstm_sample(scaler.transform(s)))\n",
    "\n",
    "# Choose a test sample, one which does not already fool the model\n",
    "    \n",
    "for (idx, path) in enumerate(data_paths):\n",
    "    if idx == 2:\n",
    "        continue\n",
    "    correct = False\n",
    "    while not correct:\n",
    "        candidate_choice = scaled_sliced_data[path].pop()\n",
    "        vals, counts = np.unique(stacked_cnn_lstm_sae.predict(candidate_choice).argmax(axis=-1), return_counts=True)\n",
    "        mr = vals[np.argmax(counts)]\n",
    "        print(mr, idx)\n",
    "        correct = (mr == idx)\n",
    "    test_samples[path] = candidate_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4892ee28-7921-4c2c-a879-738250e9cffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p2p_sample_data = np.loadtxt(\"Data/p2p-sample.csv\", delimiter=',')\n",
    "# browse_sample_data = np.loadtxt(\"Data/browse-sample.csv\", delimiter=',')\n",
    "# chat_sample_data = np.loadtxt(\"Data/mail-sample.csv\", delimiter=',')\n",
    "\n",
    "# scaled_p2p_sample_data = scaler.transform(p2p_sample_data)\n",
    "# scaled_browse_sample_data = scaler.transform(browse_sample_data)\n",
    "# scaled_chat_sample_data = scaler.transform(chat_sample_data)\n",
    "\n",
    "p2p_sample = test_samples['Data/p2p/']\n",
    "browse_sample = test_samples['Data/browse/']\n",
    "chat_sample = test_samples['Data/chat/']\n",
    "\n",
    "\n",
    "p2p_label = np.tile(np.array([0.0, 0.0, 0.0, 1.0]),(1, 1))\n",
    "browse_label = np.tile(np.array([1.0, 0.0, 0.0, 0.0]), (1, 1))\n",
    "chat_label = np.tile(np.array([0.0, 1.0, 0.0, 0.0]), (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbef74b3-77af-4b72-ac68-d7d8c5df264f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Additional helper functions\n",
    "\n",
    "def get_jacobian(forward_derivative, idx, target_label):\n",
    "    return forward_derivative[(target_label,) + idx]\n",
    "\n",
    "def input_shape_range(shape):\n",
    "    return iprod(*(range(s) for s in shape))\n",
    "\n",
    "def make_result_sane(inp):\n",
    "    result = np.copy(inp)\n",
    "    result[0] = np.ceil(inp[0])\n",
    "    result[1] = np.ceil(inp[1])\n",
    "    result[2] = 100*result[0]\n",
    "    result[3] = 8*result[1]*100\n",
    "    result[4] = inp[4] if result[0] > 1 else 0\n",
    "    result[5] = result[1]/result[0] if result[0] != 0 else 0\n",
    "    return result\n",
    "    \n",
    "def predict(model, inp):\n",
    "    # This is used to take the output of a softmax classifier of \n",
    "    # the type found in this paper\n",
    "    # and get the prediction in terms of one-hot encoding.\n",
    "    \n",
    "    output_size = model.output_shape[1]\n",
    "    res1 = model.predict(inp).argmax(axis=1)\n",
    "    vals, counts = np.unique(res1, return_counts=True)\n",
    "    res = vals[np.argmax(counts)]\n",
    "    return res1, np.eye(output_size)[res]\n",
    "    # output_size = model.output_shape[1]\n",
    "    # res1 = tf.argmax(model(inp), axis=1)\n",
    "    # vals, _, counts = tf.unique_with_counts(res1)\n",
    "    # res = vals[tf.argmax(counts)]\n",
    "    # return res1, np.eye(output_size)[res]\n",
    "\n",
    "@tf.function\n",
    "def predict_one(model, inp):\n",
    "    res = tf.argmax(model(inp))[0]\n",
    "    return res\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def saliency_map(forward_derivative, input_shape, l, output_size):\n",
    "    s = dict()\n",
    "    for idx in input_shape_range(input_shape):\n",
    "        g = get_jacobian(forward_derivative, idx, l)\n",
    "        if g < 0:\n",
    "            s[idx] = tf.experimental.numpy.float64(0)\n",
    "        else:\n",
    "            t = tf.experimental.numpy.float64(0)\n",
    "            for j in range(output_size):\n",
    "                if j != l:\n",
    "                    t += get_jacobian(forward_derivative, idx, j)\n",
    "            if t > 0:\n",
    "                s[idx] = tf.experimental.numpy.float64(0)\n",
    "            else:\n",
    "                s[idx] = g*tf.abs(t)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def reverse_scaler(scaler, scaled_input):\n",
    "    res = np.copy(scaled_input)\n",
    "    if scaler.with_std:\n",
    "        res *= scaler.scale_\n",
    "    if scaler.with_mean:\n",
    "        res += scaler.mean_\n",
    "    return res\n",
    "\n",
    "def scale(scaler):\n",
    "    def _(inp):\n",
    "        res = np.copy(inp)\n",
    "        if scaler.with_mean:\n",
    "            res -= scaler.mean_\n",
    "        if scaler.with_std:\n",
    "            res /= scaler.scale_\n",
    "        return res\n",
    "    return _\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def jacobian(model, adversarial_sample, input_shape, output_size):\n",
    "    with tf.GradientTape() as tape:\n",
    "        a = adversarial_sample\n",
    "        tape.watch(a)\n",
    "        prediction = model(a)\n",
    "    return tf.reshape(tape.jacobian(prediction, a),\n",
    "                    (output_size,) + input_shape[1:])\n",
    "\n",
    "## The key routine used to create adversarial examples here\n",
    "\n",
    "def create_adversarial_sample(sample, model, target_label, max_distortion, theta):\n",
    "    adversarial_sample = np.copy(sample)\n",
    "    input_shape = sample.shape\n",
    "    output_size = model.output_shape[1]\n",
    "    delta = 0\n",
    "    while (not np.equal(predict_one(model, adversarial_sample), target_label).all() and delta < max_distortion):\n",
    "        forward_derivative = jacobian(model, adversarial_sample, input_shape, output_size)\n",
    "        s = saliency_map(forward_derivative, input_shape[1:], target_label.argmax(), output_size)\n",
    "        # Argmax over dict entries\n",
    "        argmax_res, curr_max = None, None\n",
    "        for idx in s.keys():\n",
    "            if not curr_max or s[idx] > curr_max:\n",
    "                curr_max = s[idx]\n",
    "                argmax_res = idx\n",
    "        adversarial_sample[0][argmax_res] += theta\n",
    "        delta = np.linalg.norm(adversarial_sample - sample)\n",
    "    return adversarial_sample\n",
    "    \n",
    "def create_adversarial_sample_lstm(sample, model, target_label, max_distortion, theta):\n",
    "    results = []\n",
    "    for timeseries_idx in range(sample.shape[0]):\n",
    "        subsample = sample[timeseries_idx].reshape((1,5,6))\n",
    "        adversarial_subsample = create_adversarial_sample(subsample, model, target_label, max_distortion, theta)\n",
    "        results.append(adversarial_subsample)\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf76a17-d6f8-4302-9e38-04dd690ee31b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "theta = 0.01\n",
    "sample_label_combos = [(p2p_sample, browse_label), (browse_sample, p2p_label), (chat_sample, browse_label),\n",
    "                       (p2p_sample, chat_label), (browse_sample, chat_label), (chat_sample, p2p_label)]\n",
    "\n",
    "with open('jsma.log', 'a') as logfile:\n",
    "    for (sample, label) in sample_label_combos:\n",
    "        print(\"Target label:\", label, file=logfile)\n",
    "        print(\"Scaled Sample:\", sample, file=logfile)\n",
    "        r1, r = predict(stacked_cnn_lstm_sae, sample)\n",
    "        print(\"Majority prediction:\", r1, file=logfile)\n",
    "        print(\"Individual predictions:\", r, file=logfile)\n",
    "        print(\"ADVERSARIAL SAMPLES:\\n\\n\", file=logfile)\n",
    "        for max_distortion in [0.1, 1, 10, 20, 50]:\n",
    "            print(\"max distortion =\", max_distortion, file=logfile)\n",
    "            adv = create_adversarial_sample_lstm(sample, stacked_cnn_lstm_sae, label, max_distortion, theta)\n",
    "            print(\"Adversarial raw:\", adv, file=logfile)\n",
    "            adv2 = adv.reshape((-1, 5, 6))\n",
    "            adv3 = reverse_scaler(scaler, adv2)\n",
    "            print(\"Unscaled adversarial:\", adv3, file=logfile)\n",
    "            adv4 = np.apply_along_axis(make_result_sane, 2, adv3)\n",
    "            print(\"Unscaled adversarial made sane:\", adv4, file=logfile)\n",
    "            scaled_adversarial = np.apply_along_axis(scale(scaler), 2, adv4)\n",
    "            print(\"Scaled adversarial made sane:\", scaled_adversarial, file=logfile)\n",
    "            print(\"Sample difference:\", scaled_adversarial-sample, file=logfile)\n",
    "            r1, r = predict(stacked_cnn_lstm_sae, scaled_adversarial)\n",
    "            print(\"Majority prediction:\", r1, file=logfile)\n",
    "            print(\"Individual predictions:\", r, file=logfile)\n",
    "            print(\"\\n\", file=logfile)\n",
    "        print(\"\\n\", file=logfile)\n",
    "    print(\"END LOG\", file=logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0d872-3ca4-43a8-b9c7-57a66b301797",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
